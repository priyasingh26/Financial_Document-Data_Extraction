{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YptJaSKq4xbH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ronak\\anaconda3\\envs\\insta\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import torch\n",
        "from transformers import LayoutLMTokenizer, LayoutLMForSequenceClassification\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of LayoutLMForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = LayoutLMTokenizer.from_pretrained(\"microsoft/layoutlm-base-uncased\")\n",
        "model = LayoutLMForSequenceClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\", num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SiRmsx0g5KnN"
      },
      "outputs": [],
      "source": [
        "def load_images_from_directory(base_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for doc_type in os.listdir(base_dir):\n",
        "        doc_type_path = os.path.join(base_dir, doc_type)\n",
        "        if os.path.isdir(doc_type_path):\n",
        "            for filename in os.listdir(doc_type_path):\n",
        "                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
        "                    img_path = os.path.join(doc_type_path, filename)\n",
        "                    try:\n",
        "                        img = cv2.imread(img_path)\n",
        "                        if img is None:\n",
        "                            raise ValueError(f\"Unable to read image: {img_path}\")\n",
        "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                        images.append((filename, img))\n",
        "                        labels.append(doc_type)\n",
        "                        logging.info(f\"Successfully loaded: {img_path}\")\n",
        "                    except Exception as e:\n",
        "                        logging.error(f\"Error loading {img_path}: {str(e)}\")\n",
        "    return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ORVYLlM55eS2"
      },
      "outputs": [],
      "source": [
        "def perform_ocr(image):\n",
        "    try:\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            raise ValueError(\"Input to perform_ocr must be a numpy array\")\n",
        "        pil_image = Image.fromarray(image)\n",
        "        text = pytesseract.image_to_string(pil_image)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        logging.error(f\"OCR error: {str(e)}\")\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_document(text):\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    return predictions.argmax().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wz1QgFR15sjE"
      },
      "outputs": [],
      "source": [
        "def extract_info(text):\n",
        "    # This is a placeholder function. In a real-world scenario, you'd use a more sophisticated\n",
        "    # named entity recognition model or rule-based system to extract specific information.\n",
        "    info = {\n",
        "        \"text_length\": len(text),\n",
        "        \"numeric_values\": [num for num in text.split() if num.replace('.', '').isdigit()],\n",
        "        \"possible_dates\": [word for word in text.split() if '/' in word or '-' in word]\n",
        "    }\n",
        "    return info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GrSptQPF5uJd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    base_dir = './archive'\n",
        "    images, labels = load_images_from_directory(base_dir)\n",
        "    \n",
        "    if not images:\n",
        "        logging.error(\"No valid images found. Please check your directory and image files.\")\n",
        "        return\n",
        "\n",
        "    data = []\n",
        "    le = LabelEncoder()\n",
        "    encoded_labels = le.fit_transform(labels)\n",
        "\n",
        "    for (filename, image), label, encoded_label in zip(images, labels, encoded_labels):\n",
        "        logging.info(f\"Processing image: {filename}\")\n",
        "        \n",
        "        text = perform_ocr(image)\n",
        "        logging.info(f\"OCR result for {filename}: {text[:100]}...\")  # Log the first 100 characters of each OCR result\n",
        "        \n",
        "        if text.strip():\n",
        "            predicted_class = classify_document(text)\n",
        "            info = extract_info(text)\n",
        "            info['filename'] = filename\n",
        "            info['true_label'] = label\n",
        "            info['predicted_label'] = le.inverse_transform([predicted_class])[0]\n",
        "            info['correct_prediction'] = (predicted_class == encoded_label)\n",
        "            data.append(info)\n",
        "        else:\n",
        "            logging.warning(f\"Empty text extracted from {filename}. Skipping this image.\")\n",
        "\n",
        "    if not data:\n",
        "        logging.error(\"No valid texts extracted from images. Cannot proceed with classification.\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    accuracy = (df['correct_prediction'].sum() / len(df)) * 100\n",
        "    logging.info(f\"Model accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    logging.info(\"DataFrame head:\")\n",
        "    logging.info(df.head())\n",
        "    \n",
        "    df.to_csv('extracted_document_info.csv', index=False)\n",
        "    logging.info(\"Data saved to 'extracted_document_info.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "0K7ZYcAJ5w39",
        "outputId": "afdcb4af-3d8a-4e54-8132-af34b08b4081"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Error loading ./archive\\Bank Statement\\50.jpg: Unable to read image: ./archive\\Bank Statement\\50.jpg\n",
            "ERROR:root:Error loading ./archive\\Check\\70.jpg: Unable to read image: ./archive\\Check\\70.jpg\n",
            "ERROR:root:Error loading ./archive\\ITR_Form 16\\34.jpg: Unable to read image: ./archive\\ITR_Form 16\\34.jpg\n",
            "ERROR:root:Error loading ./archive\\ITR_Form 16\\37.jpg: Unable to read image: ./archive\\ITR_Form 16\\37.jpg\n",
            "ERROR:root:Error loading ./archive\\ITR_Form 16\\39.jpg: Unable to read image: ./archive\\ITR_Form 16\\39.jpg\n",
            "ERROR:root:Error loading ./archive\\ITR_Form 16\\42.jpg: Unable to read image: ./archive\\ITR_Form 16\\42.jpg\n",
            "ERROR:root:Error loading ./archive\\Salary Slip\\23.jpg: Unable to read image: ./archive\\Salary Slip\\23.jpg\n",
            "ERROR:root:Error loading ./archive\\Salary Slip\\41.jpg: Unable to read image: ./archive\\Salary Slip\\41.jpg\n",
            "ERROR:root:Error loading ./archive\\Utility\\11.jpg: Unable to read image: ./archive\\Utility\\11.jpg\n",
            "ERROR:root:Error loading ./archive\\Utility\\31.jpg: Unable to read image: ./archive\\Utility\\31.jpg\n",
            "ERROR:root:Error loading ./archive\\Utility\\5.jpg: Unable to read image: ./archive\\Utility\\5.jpg\n",
            "WARNING:root:Empty text extracted from 2.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 12.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 13.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 23.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 39.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 50.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 56.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 57.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 7.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 74.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 79.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 89.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 90.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 94.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 97.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 1.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 12.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 14.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 26.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 3.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 4.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 101.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 39.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 43.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 50.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 67.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 83.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 10.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 19.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 34.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 4.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 56.jpg. Skipping this image.\n",
            "WARNING:root:Empty text extracted from 73.jpg. Skipping this image.\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "insta",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
